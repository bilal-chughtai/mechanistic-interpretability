{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import einops\n",
    "import sage\n",
    "\n",
    "import json\n",
    "import pickle \n",
    "import copy\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# plotting\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import plotly.graph_objects as go\n",
    "pio.renderers.default = \"vscode\"\n",
    "\n",
    "# my own tooling\n",
    "from utils.hook_points import HookPoint, HookedRootModule\n",
    "from utils.plotting import *\n",
    "from utils.groups import *\n",
    "from utils.models import *\n",
    "from utils.config import *\n",
    "\n",
    "if torch.cuda.is_available:\n",
    "  print('Good to go!')\n",
    "else:\n",
    "  print('Things might be rather slow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_dir = \"mainline-S5\" #1L_MLP_sym_S5_cached_3\"\n",
    "seed, frac_train, layers, lr, group_param, weight_decay, num_epochs, group_type, architecture_type, metric_cfg, metric_obj = load_cfg(task_dir)\n",
    "group = group_type(group_param, init_all = True)\n",
    "all_data, _, all_labels, _ = generate_train_test_data(group, frac_train = 1)\n",
    "model = architecture_type(layers, group.order, seed).cuda()\n",
    "model.load_state_dict(torch.load(f\"{task_dir}/model.pt\"))\n",
    "model.eval()\n",
    "logits, activations = model.run_with_cache(all_data, return_cache_object=False)\n",
    "activations['logits'] = logits\n",
    "metric_obj = metric_obj(group, training=False, track_metrics = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logit Attribution\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings and Unembeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden Layer Neurons"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logit Computation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ablations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Circuit Analysis: Sign rep\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10 (default, Jun 22 2022, 20:18:18) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2132269f5a2133219c4d2300f20c817fe4655a4b6c81d581573bf57d15b76d41"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
